---
title:  "Super Resolution Survey 3. Unsupervised Super-Resolution"
search: true
categories:
  - Super Resolution
date: March 28, 2021
summary: This post is the third part of the summary of SR survey paper.
toc: true
toc_sticky: true
header:
  teaser: /assets/images/thumbnails/thumb_basic.jpg
tags:
  - Deep Learning
  - Super Resolution
last_modified_at: 2021-03-28T08:06:00-05:00
---

The main objective of this work is to provide an overall idea on super resolution and its related models. Based on the flow of this survey paper, I supplemented some explanations by referring to other articles or papers. This post is just a summary of the summary paper below, so if you want to look into the contents in detail, you can click the links I left.  

[Deep Learning for Image Super-Resolution: A Survey](https://arxiv.org/pdf/1902.06068.pdf).  

<br>


### 4. Unsupervised Super-Resolution  

Existing super-resolution works mostly focus on supervised learning (i.e., learning with matched LR-HR image pairs) However, since it is difficult to collect images of the same scene but with different resolutions, the LR images in SR datasets are often obtained by performing predefined degradation on HR images. Thus the trained SR models actually learn a reverse process of the predefined degradation.  
In order to learn the real-world LR-HR mapping without introducing manual degradation priors, researchers pay more and more attention to unsupervised SR, in which case only unpaired LR-HR images are provided for training, so that the resulting models are more likely to cope with the SR problems in real-world scenarios. Next we'll briefly introduce several existing unsupervised SR models with deep learning, and more methods are yet to be explored.  

#### (1) Zero-shot Super-resolution  

Considering that the internal image statistics inside a single image have provided sufficient information for SR, ZSSR (Zero-shot SR) is proposed to cope with unsupervised SR by training image-specific SR networks at test time rather than training a generic model on large external datasets. Specifically, they estimate the degradation kernel from a single image using [Nonparametric Blind Super-Resolution](https://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Michaeli_Nonparametric_Blind_Super-resolution_2013_ICCV_paper.pdf) and this kernel to build a small dataset by performing degradation with different scaling factors and augmentation on this image. Then a small CNN for SR is trained on this dataset and used for the final prediction.  
In this way, the ZSSR leverages on the cross-scale internal recurrence inside every image, and thus outperforms previous approaches by a large margin on images under non-ideal conditions, which is closer to the real-world scenes, while give competitive results under ideal conditions. However, since it needs to train different networks for different images during testing, the inference time is much longer than others.  


#### (2) Weakly-supervised Super-resolution  

To cope with super-resolution without introducing predefined degradation, researchers attempt to learn SR models with weakly-supervised learning (i.e., using unpaired LR-HR images). Among them, some researchers first learn the HR-to-LR degradation and use it to construct datasets for training the SR model, while others design cycle-in-cycle networks to learn the LR-to-HR and HR-to-LR mappings simultaneously.  

**Learned Degradation**  
Since the predefined degradation is suboptimal, learning the degradation from unpaired LR-HR datasets is a feasible direction. A method propose a two-stage process which firstly trains an HR-to-LR GAN to learn degradation using unpaired LR-HR images and then trains an LR-to-HR GAN for SR using paired LR-HR images conducted based on the first GAN. Specifically, for the HR-to-LR GAN, HR images are fed into the generator to produce LR outputs, which are required to match not only the LR images obtained by downsampling the HR images (by average pooling) but also the distribution of real LR images. After finishing training, the generator is used as a degradation model to generate LR-HR image pairs. Then for the LR-to-HR GAN, the generator (i.e., the SR model) takes the generated LR images as input and predicts HR outputs, which are required to match not only the corresponding HR images but also the distribution of the HR images.  
By applying this two-stage process, the proposed unsupervised model effectively increases the quality of super resolving real-world LR images.  

**Cycle-in-cycle Super-resolution**  
Another approach for unsupervised super-resolution is to treat the LR space and the HR space as two domains, and use a cycle-in-cycle structure to learn the mappings between each other. In this case, the training objectives include pushing and mapped results to match the target domain distribution and making the images recoverable through rough-trip mappings.
- CycleGAN, CinCGAN (Cycle-in-cycle SR network)  
Because of avoiding the predefined degradation, the unsupervised CinCGAN not only achieves comparable performance to supervised methods, but also is applicable to various cases even under very harsh conditions. However, due to the ill-posed essence of SR problem and the complicated architecture of CinCGAN, some advanced strategies are needed for reducing the training difficulty and instability.  


#### (3) Deep Image Prior  

Considering that the CNN structure is sufficient to capture a great deal of low-level image statistics, a method employ randomly-initialized CNN as handcrafted prior to perform SR. Specifically, they define a generator network which takes a random vector *z* as input and tries to generate the target HR image *I<sub>y</sub>*. The goal is to train the network to find an *I&#770;<sub>y</sub>* that the downsampled *I&#770;<sub>y</sub>* is identical to the LR image *I<sub>x</sub>*. Since the network is randomly initialized and never trained, the only prior is the CNN structure itself. Although the performance of this method is still worse than the supervised methods, it outperforms traditional bicubic upsampling considerable.  

<br>

### 5. Domain-specific Applications  

#### (1) Depth Map Super-Resolution  
Depth maps record the depth (i.e., distance) between the viewpoint and objects in the scene, and plays important roles in many tasks like pose estimation and semantic segmentation. However, due to economic and production constraints, the depth maps produced by depth sensors are often low-resolution and suffer degradation effects such as noise, quantization and missing values. Thus SR is introduced for increasing the spatial resolution of depth maps.  


#### (2) Face Image Super-Resolution  
Face image SR (a.k.a face hallucination) can often help other face-related tasks. Compared to generic images, face images have more face-related structured information, so incorporating facial prior knowledge (e.g., landmarks, parsing maps, identities) into FH is a very popular and promising approach.  
- CBN, Super-FAN, MTUN, FSRNet, SICNN, TDN, TDAE, LCGE  
- Attention-FH, UR-DGN, multi-class GAN-based FH model  


#### (3) Hyperspectral Image Super-Resolution  
Compared to panchromatic images (PANs, i.e., RGB images with 3 bands), hyperspectral images (HSIs) containing hundreds of bands provide abundant spectral features and help various vision tasks. However, due to hardware limitations, collecting high-quality HSIs is much more difficult than PANs and the resolution is also lower. Thus SR is introduced into this field, and researchers tend to combine HR PANS and LR HSIs to predict HR HSIs.  


#### (4) Real-world Image Super-Resolution  
Generally, the LR images for training SR models are generated by downsampling RGB images manually (e.g., by bicubic downsampling). However, real-world cameras actually capture 12-bit or 14-bit RAW images, and performs a series of operations (e.g., demosaicing, denoising and compression) through camera ISPs (image signal processors) and finally produce 8-bit RGB images. Through this process, the RGB images have lost lots of original signals and are very different from the original images taken by the camera. Therefore, it is suboptimal to directly use the manually downsampled RGB image for SR.  


#### (5) Video Super-Resolution  
For video super-resolution, multiple frames provide much more scene information, and there are not only intra-frame spatial dependency but also inter-frame temporal dependency (e.g., motions, brightness and color changes). Thus the existing works mainly focus on making better use of spatio-temporal dependency, including explicit motion compensation (e.g., optical flow-based, learning-based) and recurrent methods, etc.  
- Optical flow-based methods: VSRnet, CVSRnet  
- Learning the motion compensation: VESPCN  
- Using reccurent methods: BRCN, STCN, FRVSR, FSTRN, RBPN  


#### (6) Other Applications  
Deep learning based SR is also adopted to other domain-specific applications and shows great performance.  
- Perceptual GAN: small object detection problem  
- FSR-GAN: image retrieval  
All in all, super-resolution technology can play an important role in all kinds of applications, especially when we can deal with large objects well but cannot handle small objects.  

<br>

### 6. Conclusion and Future directions  

Despite great success, there are still many unsolved problems. Thus in this section, we will point out these problems explicitly and introduce some promising trends for future evolution.  


#### (1) Network Design  
Good network design not only determines a hypothesis space with great performance upper bound, but also helps efficiently learn representations without excessive spatial and computational redundancy. Below the authors introduce some promising directions for network improvements.  
*Combining Local and Global Information*. Large receptive field provides more contextual information and helps generate more realistic results. Thus it is promising to combine local and global information for providing contextual information of different scales for image SR.  
*Combining Low-and High-level Information*. Shallow layers in CNNs tend to extract low-level features like colors and edges, while deeper layers learn higher-level representations like object identities. Thus combining low-level details with high-level semantics can be of great help for HR reconstruction.  
*Context-specific Attention*. In different contexts, people tend to care about different aspects of the images. For example, for the grass area people may be more concerned with local colors and textures, while in the animal body area people may care more about the species and corresponding hair details. Therefore, incorporating attention mechanism to enhance the attention to key features facilitates the generation of realistic details.  
*More Efficient Architectures*. Existing SR models tend to pursue ultimate performance, while ignoring the model size and inference speed. For example, EDSR takes 20s per image (for x4 SR on DIV2K with Titan GTX GPU). Such long prediction time is unacceptable in practical applications, thus more efficient architectures are imperative. How to reduce model size and speed up prediction while maintaining performance remains a problem.  
*Upsampling Methods*. Existing upsampling method have more or less disadvantages:
- Interpolation methods: expensive computation, can't be end-to-end learned  
- Transposed convolution: Produces checkerboard artifacts  
- Sub-pixel layer: uneven distribution of receptive fields  
- Meta upscale module: instability or inefficiency  
How to perform effective and efficient upsampling still needs to be studied, especially with high scaling factors. (+NAS (Neural Architecture Search))  


#### (2) Learning Strategies  
Besides good hypothesis spaces, robust learning strategies are also needed for achieving satisfactory results.  
*Loss Functions*. Existing loss functions can be regarded as establishing constraints among LR/HR/SR images, and guide optimization based on whether these constraints are met. In practice, these loss functions are often weighted combined and the best loss function for SR is still unclear. Therefore, one of the most promising directions is to explore the potential correlations between these images and seek more accurate loss functions.  
*Normalization*. Although BN is widely used in vision tasks, which greatly speeds up training and improves performance, it is proven to be sub-optimal for SR. Thus other effective normalization techniques for SR are needed to be studied.  


#### (3) Evaluation Metrics  
Evaluation metrics are one of the most fundamental components for machine learning. Metrics for SR face challenges and need more exploration.  
*More Accurate Metrics*.  
- PSNR: result in excessive smoothness and results can vary wildly between almost indistinguishable images  
- SSIM: cannot measure perceptual quality accurately  
- MOS: needs to take a lot of efforts and is non-reproducible  
Although researchers have proposed various metrics, but currently there is no unified and admitted evaluation metrics for SR quality. Thus more accurate metrics for evaluation reconstruction quality are urgently needed.  
*Blind IQA Methods*. Today most metrics used for SR are all-reference methods (i.e., assuming that we have paired LR-HR images with perfect quality). But since it's difficult to obtain such datasets, the commonly used datasets for evaluation are often conducted by manual degradation. In this case, the task we perform evaluation on is actually the inverse process of the predefined degradation. Therefore, developing blind IQA methods also has great demands.  


#### (4) Unsupervised Super-resolution  
It is often difficult to collect images with different resolutions of the same scene, so bicubic interpolation is widely used for constructing SR datasets. However, the SR models trained on these datasets may only learn the inverse process of the predefined degradation. Therefore, how to perform unsupervised super-resolution (i.e., trained on datasets without paired LR-HR images) is a promising direction for future development.  


#### (5) Towards Real-world Scenarios  
Image Super-resolution is greatly limited in real-world scenarios, such as suffering unknown degradation, missing paired LR-HR images.  
*Dealing with Various Degradation*. Real-world images tend to suffer degradation like blurring, additive noise and compression artifacts. Thus the models trained on datasets conducted manually often perform poorly in real-world scenes. Some works have been proposed for solving this, but these methods have some inherent drawbacks, such as great training difficulty and over-perfect assumptions.  
*Domain-specific Applications*. SR can not only be used in domain-specific data and scenes directly, but also help other vision tasks greatly. Therefore, it is also a promising direction to apply SR to more specific domains, such as video surveillance, object tracking, medical imaging and scene rendering.  
