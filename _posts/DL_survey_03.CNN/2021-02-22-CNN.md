---
title:  "Deep Learining survey_3.CNN"
search: true
categories:
  - Deep learning
classes: wide
summary: This post is the third part (CNN section) of summary of a survey paper.
last_modified_at: 2021-02-22T08:06:00-05:00
---


This post is the third part (CNN section) of summary of a survey paper
[A state-of-the Art survey on Deep learning theory and architecture](https://www.mdpi.com/2079-9292/8/3/292).  
This part is the basics of CNNs so, if you have already known them, you can skip this part.


### 3.1. CNN overview  

**1988 (Fukushima):** the CNN network was first proposed but was not widely used due to limits of computation hardware for training the network.  
**1990s (LeCun):** A gradient-based learning algorithm was applied to CNNs and obtained successful results for the handwritten digit classification problem.  
*** Several advantages of CNNs over DNNs:**
Being more like the human visual processing system.  
Being highly optimized in the structure for processing 2D and 3D images.  
Being effective at learning and extracting abstractions of 2D features.  
The max pooling layer of CNNs is effective in absorbing shape variations.  
CNNs have significantly fewer parameters than a fully connected network of similar size (composed of sparse connections with tied weights)
CNNs are trained with the gradient-based learning algorithm and suffer less from the diminishing gradient problem.  


Figure 1 show the overall architecture of CNNs consists of two main parts: feature extractors and a classifier.
Feature extraction layers: Each layer of the network receives the output from its immediate previous layer as its input and passes its output as the input to the next level.

* The CNN architecture consists of a combination of three types of layers: Convolution, max-pooling and Classification.  

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/Figure1.png" style="width:40%">
  <figcaption>Fig.1 - The averall architecture of CNNs.</figcaption>
</p>

- Each plane of a layer is usually derived from the combination of one or more planes of previous layers.  
- The nodes of a plane are connected to the small region of each connected planes of the previous layer.  
- Each node of the convolution layer extracts the features from the input images by convolution operations on the input nodes.
- As the features propagate to the highest layer or level, the dimensions of features are reduced depending on the size of the kernel for the convolutional and max-pooling operations respectively.  
- However, the number of feature maps usually increased for representing better features of the input images for ensuring classification accuracy.  
- The output of the last layer of the CNN is used as the input to a fully connected network which is called classification layer.  
- The fully connected layers are expensive in terms of network or learning parameters, so nowadays, there are several new techniques including average pooling and global average pooling that is used as an alternative of fully-connected networks.  
- The score of the respective class is calculated in the top classification layer using a soft-max layer. Based on the highest score, the classifier gives output for the corresponding classes.  



Later, we will discuss about mathematical details on different layers of CNNs (Convolutional layer, pooling layer, classification layer).

### 3.1.1. Convolutional Layer  

- In this layer, feature maps from previous layers are convolved with learnable kernels.  
- The output of the kernels goes through a linear or non-linear activation function, such as signoid, tanh, softmax, ReLU, ...) to form the output feature maps.  
- Each of the output feature maps can be combined with more than one input feature map.  

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/equation1.png" style="width:10%">
</p>

- x^l_j: the output of the current layer.  
- x^l-1_i: the previous layer output.  
- k^l_ij: the kernel for the present layer. (the input maps will be convolved with distinct kernels to generate the corresponding output maps)  
- b^l_j: the biases for the current layer. (for each output map, an additive bias b is given)  
- M_j: a selection of input maps.  
- f: activation function (such as sigmoid, tanh, softmax, ReLU, ...)  


### 3.1.2. Sub-sampling Layer  

- The subsampling layer performs the down sampled operation on the input maps.
- This is commonly known as the pooling layer.  
- In this layer, the number of input and output feature maps does not change.
- Due to the down sampling operation, the size of each dimension of the output maps will be reduced, depending on the size of the down sampling mask.  

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/equation2.png" style="width:10%">
</p>

- down(.): a sub-sampling function.
- Two types of operations are mostly performed in this layer: average pooling (selects the average value) or max-pooling (selects the highest value)  
- Some alternative sub-sampling layers have been proposed, such as fractional max-pooling and sub-sampling with convolution.  



### 3.1.3. Classification Layer  

- The fully connected layer which computes the score of each class from the extracted features from a convolutional layer in the preceding steps.
- The fully connected feed-forward neural layers are used as a soft-max classification layer.  
- In most cases, two or four layers of layers are incorporated in the network model.  
- As the fully connected layers are expensive in terms of computation, alternative approaches have been proposed. (global average pooling layer, average pooling layer)  

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/Figure2.png" style="width:40%">
  <figcaption>Fig.1 - The basic operations in the convolution and sub-sampling of an input image.</figcaption>
</p>



### 3.1.4. Network Parameters and Required Memory for CNN  





I'll organize deep learning concepts according to the history of deep learning with keywords.  
Before we get the concepts of Deep learning, we will look over the basic concepts from learning.


**Learning:** A procedure consisting of estimating the model parameters so that the learned model (algorithm) can perform a specific task.


### 1.1 Deep learning approaches can be categorized as follows:
Supervised, Semi-supervised (partially supervised), unsupervised  
(Another category of learning approach called Reinforcement Learning, Deep RL)

**Supervised learning:** A learning technique that uses labeled data.   
 - the environment has a set of inputs and corresponding outputs
 - DNN, CNN, RNN (LSTM, GRU)

**Semi-supervised learning:** learning that occurs based on partially labeled datasets.  
 - In some cases, DRL and Generative Adversarial Networks are used as semi-supervised learning technique
 - RNN (LSTM, GRU)

**Unsupervised learning systems:** ones that can without the presence of data labels.  
 - The agent learns the internal representation or important features to discover unknown relationships or structure within the input data.
 - Clustering, Dimensionality reduction, Generative techniques
 - Auto-Encoders (AE), Resticted Boltzmann Machines (RBM), GAN, RNNs (LSTM, GRU)

**Deep reinforcement learning:** A learning technique for use in unknown environments.  
 - Do not have a straight forward loss function, thus making learning harder compared to traditional supervised approaches

 *** The fundamental differences between RL and supervised learning:**  
 (1) Do not have full access to the function you are trying to optimize (you must query them through interaction)  
 (2) interacting with a state-based environment (Input depends on previous actions)  


<p>
  <img src="/assets/images/blog/DL_survey_introduction/Figure2.png" style="width:40%">
  <figcaption>Fig.1 - Category of deep learning approaches.</figcaption>
</p>


### 1.2 Feature Learning

**Definition)**  
**Machine Learning:** An application of artificial intelligence that provides systems the ability to automatically learn and improve from experience without being explicitly programmed  
**Deep Learning:** A subfield of machine learning based on artificial neural networks with representation learning.


A key difference between traditional ML and DL is in how features are extracted.  
**Traditional ML:** handcrafted engineering features by applying several feature extraction algorithm, and then apply the learning algorithms  
**DL:** the features are learned automatically and are represented hierarchically in multiple levels.


Table 1 shows the difference feature-based learning approaches with different learning steps.
<br>

<p>
  <img src="/assets/images/blog/DL_survey_introduction/Table1.png" style="width:80%">
  <figcaption>Table.1 - Different feature learning approaches.</figcaption>
</p>


### 1.3 Why DL?

1) Universal Learning Approach: It can be applied to almost any application domain  
2) Robust: Do not require the precisely designed feature.  
3) Generalization: The same DL approach can be used in different applications or with different data types.  
- This approach is often called transfer learning
- This approach is helpful where the problem does not have sufficient available data.

4) Scalability: The DL approach is highly scalable  
- Ex) ResNet contains 1202 layers and is often implemented at a supercomputing scale.  


I will skip 1.4, 1.5 contents, you can see them on page 4-7.  


### 1.6 Challenges of DL

In this section, I just wrote the keywords, and in this paper, it says that these below challenges have already been considered by the DL community.  
Moreover, you can see several survey papers based on several learning approaches from this section.

(1) Big data analytics using DL  
(2) Scalability of DL approaches  
(3) Ability to generate data  
(4) Energy efficient techniques for special purpose devices  
(5) Multi-task and transfer learning or multi-module learning  
(6) Dealing with causality in learning  
