---
title:  "Deep Learining survey_3.CNN"
search: true
categories:
  - Deep learning
classes: wide
summary: This post is the third part (CNN section) of summary of a survey paper.
last_modified_at: 2021-02-22T08:06:00-05:00
---


This post is the third part (CNN section) of summary of a survey paper
[A state-of-the Art survey on Deep learning theory and architecture](https://www.mdpi.com/2079-9292/8/3/292).  
This part is the basics of CNNs so, if you have already known them, you can skip this part.


### 3.1. CNN overview  

**1988 (Fukushima):** the CNN network was first proposed but was not widely used due to limits of computation hardware for training the network.  
**1990s (LeCun):** A gradient-based learning algorithm was applied to CNNs and obtained successful results for the handwritten digit classification problem.  
*** Several advantages of CNNs over DNNs:**
Being more like the human visual processing system.  
Being highly optimized in the structure for processing 2D and 3D images.  
Being effective at learning and extracting abstractions of 2D features.  
The max pooling layer of CNNs is effective in absorbing shape variations.  
CNNs have significantly fewer parameters than a fully connected network of similar size (composed of sparse connections with tied weights)
CNNs are trained with the gradient-based learning algorithm and suffer less from the diminishing gradient problem.  


Figure 1 show the overall architecture of CNNs consists of two main parts: feature extractors and a classifier.
Feature extraction layers: Each layer of the network receives the output from its immediate previous layer as its input and passes its output as the input to the next level.

* The CNN architecture consists of a combination of three types of layers: Convolution, max-pooling and Classification.  

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/Figure1.png" style="width:40%">
  <figcaption>Fig.1 - The averall architecture of CNNs.</figcaption>
</p>

- Each plane of a layer is usually derived from the combination of one or more planes of previous layers.  
- The nodes of a plane are connected to the small region of each connected planes of the previous layer.  
- Each node of the convolution layer extracts the features from the input images by convolution operations on the input nodes.
- As the features propagate to the highest layer or level, the dimensions of features are reduced depending on the size of the kernel for the convolutional and max-pooling operations respectively.  
- However, the number of feature maps usually increased for representing better features of the input images for ensuring classification accuracy.  
- The output of the last layer of the CNN is used as the input to a fully connected network which is called classification layer.  
- The fully connected layers are expensive in terms of network or learning parameters, so nowadays, there are several new techniques including average pooling and global average pooling that is used as an alternative of fully-connected networks.  
- The score of the respective class is calculated in the top classification layer using a soft-max layer. Based on the highest score, the classifier gives output for the corresponding classes.  



Later, we will discuss about mathematical details on different layers of CNNs (Convolutional layer, pooling layer, classification layer).

### 3.1.1. Convolutional Layer  

- In this layer, feature maps from previous layers are convolved with learnable kernels.  
- The output of the kernels goes through a linear or non-linear activation function, such as signoid, tanh, softmax, ReLU, ...) to form the output feature maps.  
- Each of the output feature maps can be combined with more than one input feature map.  

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/equation1.png" style="width:10%">
</p>

- x^l_j: the output of the current layer.  
- x^l-1_i: the previous layer output.  
- k^l_ij: the kernel for the present layer. (the input maps will be convolved with distinct kernels to generate the corresponding output maps)  
- b^l_j: the biases for the current layer. (for each output map, an additive bias b is given)  
- M_j: a selection of input maps.  
- f: activation function (such as sigmoid, tanh, softmax, ReLU, ...)  


### 3.1.2. Sub-sampling Layer  

- The subsampling layer performs the down sampled operation on the input maps.
- This is commonly known as the pooling layer.  
- In this layer, the number of input and output feature maps does not change.
- Due to the down sampling operation, the size of each dimension of the output maps will be reduced, depending on the size of the down sampling mask.  

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/equation2.png" style="width:10%">
</p>

- down(.): a sub-sampling function.
- Two types of operations are mostly performed in this layer: average pooling (selects the average value) or max-pooling (selects the highest value)  
- Some alternative sub-sampling layers have been proposed, such as fractional max-pooling and sub-sampling with convolution.  



### 3.1.3. Classification Layer  

- The fully connected layer which computes the score of each class from the extracted features from a convolutional layer in the preceding steps.
- The fully connected feed-forward neural layers are used as a soft-max classification layer.  
- In most cases, two or four layers of layers are incorporated in the network model.  
- As the fully connected layers are expensive in terms of computation, alternative approaches have been proposed. (global average pooling layer, average pooling layer)  

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/Figure2.png" style="width:40%">
  <figcaption>Fig.1 - The basic operations in the convolution and sub-sampling of an input image.</figcaption>
</p>



### 3.1.4. Network Parameters and Required Memory for CNN  

The number of computational parameters is an important metric to measure the complexity for a deep learning model.  
The size of feature maps can be formulated as follws:

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/equation3.png" style="width:10%">
</p>

- N: the dimensions of the input feature maps
- F: the dimensions of the filters or the receptive field
- M: the dimensions of output feature maps
- S: the stride length

Padding is typically applied during the convolution operations to ensure the input and output feature map have the same dimensions.  
The amount of padding depends on the size of the kernel.

Several criteria are considered for comparing the models, in most of the cases, the number of network parameters and the total amount of memory are considered.  
The number of parameters of l^th layer is the calculated based on the following equation:

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/equation4.png" style="width:10%">
</p>

If bias is added with the weights, then the above equation can be written as follows:

<p>
  <img src="/assets/images/blog/DL_survey_03.CNN/equation5.png" style="width:10%">
</p>

* The equation need to be revised to Parm_l = (F x F x (FM_l-1 + 1)) x FM_l
(**this equation need to be checked**)

FM_l: the total number of output feature maps
FM_l-1: the total number of input feature maps or channels



In the next post, I will discuss about the popular CNN architectures.
