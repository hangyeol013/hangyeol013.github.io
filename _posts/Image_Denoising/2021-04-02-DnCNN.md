---
title:  "DnCNN paper_Review"
search: true
categories:
  - Image denoising
date: April 02, 2021
summary: This post is a summary of DnCNN (image denoising using CNN) paper.
toc: true
toc_sticky: true
header:
  teaser: /assets/images/thumbnails/thumb_basic.jpg
tags:
  - Deep Learning
  - Image denoising
last_modified_at: 2021-04-03T08:06:00-05:00
---


This post is a summary of a DnCNN (image denoising using CNN) paper  
[Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising](https://arxiv.org/pdf/1608.03981.pdf).  

<br>

**Abstract**  

Discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper, the authors take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (DnCNNs) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. Specifically, `residual learning` and `batch normalization` are utilized to speed up the training process as well as boost the denoising performance.  

Different from the existing discriminative denoising models which usually train a specific model for additive white Gaussian noise (AWGN) at a certain noise level, DnCNN model is able to handle `Gaussian denoising with unknown noise level` (i.e., blind Gaussian denoising).  

*Additive white Gaussian noise (AWGN))
- Additive: because it is added to any noise that might be intrinsic to the information system.  
- White: It has uniform power across the frequency band for the information system.  
- Gaussian: It has a normal distribution in the time domain with an average time domain value of zero.  

<br>

### 1. Introduction  

*The goal of image denoising is to recover a clean image x from a noisy observation y which follows an image degradation model y = x + v*. One common assumption is that v is additive white Gaussian noise (AWGN) with standard deviation &sigma;.

In particular, the NSS (Non self-similarity) models are popular in state-of-the-art methods such as `BM3D`, LSSC, NCSR and WNNM. Despite their high denoising quality, most of the image prior-based methods typically suffer from two major drawbacks.  
1. Those methods generally involve a complex optimization problem in the testing stage, making the denoising process `time-consuming`.  
&rarr; Most of the prior-based methods can hardly achieve high performance without sacrificing computational efficiency.  
2. The models in general are `non-convex` and involve `several manually chosen parameters`, providing some leeway to boost denoising performance.  

To overcome the limitations of prior-based approaches, several discriminative learning methods (CSF, `TNRD`) have been recently developed to learn image prior models in the context of truncated inference procedure. The resulting models are able to `get rid of the iterative optimization procedure in the test phase`.  

Although CSF and TNRD have shown promising results toward bridging the gap between computational efficiency and denoising quality, their performance are inherently restricted to the specified forms of prior. To be specific, the priors adopted in CSF and TNRD are based on the analysis model, which is `limited in capturing the full characteristics` of image structures. Another nonnegligible drawback is that they train a specific model for a certain noise level, and are `limited in blind image denoising`.  

In this paper, instead of learning a discriminative model with an explicit image prior, the authors treat image denoising as `a plain discriminative learning problem`. (i.e., separating the noise from a noisy image by feed-forward convolutional neural networks).  

*Rather than directly outputting the denoised image x&#770;, the proposed DnCNN is designed to predict the residual image v&#770;*, (i.e., the difference between the noisy observation and the latent clean image). In other words, the proposed DnCNN implicitly removes the latent clean image with the operations in the hidden layers.  

The batch normalization technique is further introduced to stabilize and enhance the training performance of DnCNN. It turns out that `residual learning` and `batch normalization` can benefit from each other, and their integration is effective in speeding up the training and boosting the denoising performance.  

The contributions of this work are summarized as follows:  
1. They propose `an end-to-end trainable deep CNN` for Gaussian denoising. In contrast to the existing dnn-based methods, DnCNN adopts the residual learning strategy.  
2. They find that `residual learning` and `batch normalization` can greatly benefit the CNN learning (training speed, performance)  
3. DnCNN can be easily extended to handle `general image denoising tasks`. (blind Gaussian denoising, SISR, JPEG deblocking)  

+) The first CNN model for general image denoising (not for a certain noise level)  

<br>

### 2. The proposed Denoising CNN Model  

In this section, we'll look the proposed denoising CNN model (DnCNN, and extend it for handling several general image denoising tasks).
- Network architecture design: modified VGG network to make it suitable for image denoising.  
- Model learning: Residual learning, batch normalization.  


#### A. Network Architecture  

<p>
  <img src="/assets/images/blog/Image_Denoising/Figure1.png" style="width:100%">
  <figcaption>
  Fig.1 - The architecture of the proposed DnCNN network.
  </figcaption>
</p>

The input of DnCNN: A noisy observation *y* = *x* + v.  
The loss function: the averaged MSE between the desired residual images and estimated ones,  
<p>
  <img src="/assets/images/blog/Image_Denoising/Equation1.png" style="width:60%">
</p>
Here *{(y<sub>i</sub>, x<sub>i</sub>)}<sup>N</sup><sub>i=1</sub>* represents N noisy-clean training image (patch) pairs.



##### 1) Deep Architecture:  

The DnCNN model has two main features: the residual learning formulation and batch normalization. By incorporating convolution with ReLU, DnCNN can gradually separate image structure from the noisy observation through the hidden layer.  


##### 2) Reducing Boundary Artifacts  

In many low level vision applications, it usually requires that the output image size should keep the same as the input one. This may lead to the boundary artifacts.  
- Previous methods: symmetrically `padded in the preprocessing stage`. (MLP, CDF, TNRD)  
- DnCNN: `pad zeros before convolution` (each feature map of the middle layers has the same size as the input image)  

<br>

#### B. Integration of Residual Learning and Batch Normalization for Image Denoising  

Figure.2 shows the average PSNR values obtained using the two learning formulations (y &rarr; x (original mapping) or y &rarr; v (residual mapping)) with/without batch normalization under the same setting on gradient-based optimization algorithm and network architecture.  
<p>
  <img src="/assets/images/blog/Image_Denoising/Figure2.png" style="width:100%">
  <figcaption>
  Fig.2 - The Gaussian denoising results of four specific models under two gradient-based optimization algorithms (a) SGD, (b) Adam, with respect to epochs. The four specific models are trained with noise level 25. The results are evaluated on 68 natural images from Berkeley segmentation dataset.
  </figcaption>
</p>
1. The `residual learning` formulation can result in `faster and more stable convergence` than the original mapping learning.  
2. Without BN, simple residual with conventional SGD cannot compete with the SOTA denoising methods. (TNRD: 28.92dB)  
3. `With BN`, learning residual mapping `converges faster with better performance`.  

It is the integration of residual learning formulation and BN rather than the optimization algorithms (SGD or Adam) that leads to the best denoising performance.  

With `residual learning`, DnCNN implicitly removes the latent clean image with the operations in the hidden layers. This makes that the inputs of each layer are `Gaussian-like distributed`, `less correlated`, and `less related with image content`. Thus, residual learning can also `help BN in reducing internal covariate shift`.  

<br>

#### C. Extension to General Image Denoising  

When applied to Gaussian denoising with unknown noise, one common way is to first estimate the noise level, and then use the model trained with the corresponding noise level. This makes the denoising results affected by the accuracy of noise estimation. In addition, those methods cannot be applied to the cases with non-Gaussian noise distribution (e.g., SISR and JPEG deblocking)  

In the case of DnCNN, it can be extened for Gaussian denoising `with unknown noise level`. In the training stage, the noisy images from a wide range of noise levels (e.g., &sigma; &isin; [0, 55]) is used to train a single DnCNN model. Given a test image whose noise level belongs to the noise level range, the learned single DnCNN model can be utilized to denoise it without estimating its noise level.  

The DnCNN can be extened by learning for `a single model for several general image denoising tasks`. In the training stage, they utilize the `images with AWGN` from a wide range of noise levels, `down-sampled images` with multiple upscaling factors, and `JPEG images` with different quality factors to train a single DnCNN model. Experimental results show that the learned single DnCNN model is able to yield excellent results for any of the three general image denoising tasks.  

<br>

### 3. Experimental Results  

#### 1) Training and Testing Data  

**DnCNN-S (&sigma; = 15,25,50)**:
* 180 x 180 size (400 imagees)
* patch size: 40 x 40 (crop 128 x 1,600 patches)
* Test: BSD68, 12 images (widely used for evaluation of Gaussian denoising methods)

**DnCNN-B (blind noise, &sigma; &isin; [0, 55])**:
- 180 x 180 size (400 imagees)
- Patch size: 50 x 50 (crop 128 x 3,000 patches)
- Test: BSD68, 12 images (widely used for evaluation of Gaussian denoising methods)

**CDnCNN (blind noise, &sigma; &isin; [0, 55])**:
- 432 color images from Berkely segmentation dataset  
- Patch size: 50 x 50 (crop 128 x 3,000 patches)
- Test: BSD68 (Color version)

**DnCNN-3 (blind denoising, SISR, JPEG deblocking)**:  
- 91 images, 200 training images from the Berkeley segmentation dataset  
- Noise level from &sigma; &isin; [0, 55]  
- Bicubic downsampling and then bicubic upsampling (factors: 2, 3, 4)  
- By compressing the image with a quality factor ranging from 5 to 99  
- Patch size: 50 x 50 (crop 128 x 8,000 pairs)  


#### 2) Parameter setting and Network training:  

- Convolutional filter size: 3 x 3  
- DnCNN-S: 17 layers  
- DnCNN-B: 20 layers  
- DnCNN-3: 20 layers  
- Channel maps: 64
- MSE predicting the residual v  
- SGD (weight decay of 0.0001, momentum of 0.9)  
- Mini-batch size: 128  
- train 50 epochs  
- Learning rate: decayed exponentially from 1e-1 to 1e-4 for the 50 epochs  


#### 3) Quantitative and Qualitative Evaluation  

<p>
  <img src="/assets/images/blog/Image_Denoising/Table1.png" style="width:100%">
  <figcaption>
  Table.1 - The PSNR (dB) results of different methods on 12 widely used testing images.
  </figcaption>
</p>

- It can be seen that the proposed `DnCNN-S yields the highest PSNR` on most of the images.  
- Non-local means based methods are usually better on images with regular and repetitive structures whereas discriminative training based methods generally produce better results on images with irregular textures.  


**Gray images)**  
<p>
  <img src="/assets/images/blog/Image_Denoising/Figure3.png" style="width:100%">
  <figcaption>
  Fig.3 - Denoising results of the image 'parrot' with noise level 50.
  </figcaption>
</p>

- It can be seen that BM3D, WNNM, EPLL and MLP tend to produce over-smooth edges and textures.  
- While preserving sharp edges and fine details, TNRD is likely to generate artifacts in the smooth region.  
- In contrast, DnCNN-S and DnCNN-B can not only recover sharp edges and fine details but also yield visually pleasant results in the smooth region.  


**Color images)**
<p>
  <img src="/assets/images/blog/Image_Denoising/Figure4.png" style="width:100%">
  <figcaption>
  Fig.4 - Color image denoising results of one image from the DSD68 dataset with noise level 45.
  </figcaption>
</p>
- One can see the CBM3D generates false color artifacts in some regions whereas CDnCNN-B can recover images with more natural color.  
- In addition, CDnCNN-B can generate images with more details and sharper edges than CBM3D.  


#### 4) Run time  

<p>
  <img src="/assets/images/blog/Image_Denoising/Table2.png" style="width:100%">
  <figcaption>
  Table.2 - Run Time of different methods on various size of images. The run time on CPU (Left) and GPU (Right). Since the Run time on GPU varies greatly with respect to GPU and GPU-accelerated library, it is hard to make a fair comparison between CSF, TNRD and our proposed DnCNN.
  </figcaption>
</p>
- It can be seen that the proposed DnCNN can have a relatively high speed on CPU and it is faster than two discriminative models, MLP and CSF.  
- Though it is slower than BM3D and TNRD, by taking the image quality improvement into consideration, DnCNN is still very competitive in CPU implementation.  
- For the GPU time, the proposed DnCNN achieves very appealing computational efficiency.  


#### 5) Experiments on Learning a Single Model for Three General Image Denoising Tasks  

A single DnCNN-3 model is trained for three general image denoising tasks, including blind Gaussian denoising, SISR and JPEG image deblocking.

<p>
  <img src="/assets/images/blog/Image_Denoising/Table3.png" style="width:80%">
  <figcaption>
  Table.3 - Average PSNR (dB)/SSIM results of different methods for Gaussian denoising, SISR and JPEG image deblocking.
  </figcaption>
</p>
- Even they train a single DnCNN-3 model for the three different tasks, it still outperforms the nonblind TNRD and BM3D for Gaussian denoising.  
- For SISR, it surpasses TNRD by a large margin and is on par with VDSR.  
- For JPEG image deblocking, DnCNN-3 outperforms AR-CNN.  

<p>
  <img src="/assets/images/blog/Image_Denoising/Figure6.png" style="width:100%">
  <figcaption>
  Fig.6 - JPEG image deblocking results of 'Carnivaldolls' from LIVE1 dataset with quality factor 10.
  </figcaption>
</p>


<p>
  <img src="/assets/images/blog/Image_Denoising/Figure7.png" style="width:100%">
  <figcaption>
  Fig.7 - An example to show the capacity of DnCNN model for three different tasks.
  </figcaption>
</p>
- The input is composed by noisy images with `noise level` 15 (upper left) and 25 (lower left), `bicubic interpolated` low-resolution images with upscaling 2 (upper middle) and 3 (lower middle), `JPEG images` with quality factor 10 (upper right) and 30 (lower right).  
(The white lines in the input image are just used for distinguishing the six regions, and the residual image is normalized into the range of [0,1] for visualization)  
- *Even the input image is corrupted with different distortions in different regions, the restored image looks natural and does not have obvious artifacts*.
